{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0bc17712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# core importations\n",
    "import caveclient\n",
    "from caveclient import CAVEclient\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# dash importations\n",
    "import dash\n",
    "from dash import Dash, dcc, html, Input, Output, State, dash_table\n",
    "\n",
    "# ----------CORE DATA GATHERING FUNCTIONS-----------#\n",
    "\n",
    "# defines function to convert nm coordinates into FlyWire-usable\n",
    "def coordConvert(coords):\n",
    "    x = coords\n",
    "    x[0] /= 4\n",
    "    x[1] /= 4\n",
    "    x[2] /= 40\n",
    "    return x\n",
    "\n",
    "# defines function to convert list of coordinates in [4,4,40] resolution to root id #\n",
    "def coordsToRoot(coords):\n",
    "    import cloudvolume\n",
    "    from cloudvolume import CloudVolume\n",
    "    from caveclient import CAVEclient\n",
    "\n",
    "    # sets client #\n",
    "    client = CAVEclient(\"flywire_fafb_production\")\n",
    "\n",
    "    # sets cloud volume #\n",
    "    cv = cloudvolume.CloudVolume(\"graphene://https://prod.flywire-daf.com/segmentation/1.0/fly_v31\", use_https=True)\n",
    "\n",
    "    # determines resolution of volume #\n",
    "    res = cv.resolution\n",
    "\n",
    "    # converts coordinates using volume resolution #\n",
    "    cv_xyz = [int(coords[0]/(res[0]/4)),int(coords[1]/(res[1]/4)),int(coords[2]/(res[2]/40))]\n",
    "\n",
    "    # sets point by passing converted coordinates into 'download_point' method #\n",
    "    point = int(cv.download_point(cv_xyz, size=1))\n",
    "\n",
    "    # looks up root id for that supervoxel using chunkedgraph #\n",
    "    root_result = client.chunkedgraph.get_root_id(supervoxel_id=point)\n",
    "\n",
    "    # should give result of 82686985730511836 #\n",
    "    return root_result\n",
    "\n",
    "# defines function to get nucleus table entry using root id\n",
    "def getNucRoot(root_ids):\n",
    "    client = CAVEclient(\"flywire_fafb_production\")\n",
    "    mat_vers = max(client.materialize.get_versions())\n",
    "    nuc_df = client.materialize.query_table('nuclei_v1',\n",
    "                                            filter_in_dict={\"pt_root_id\": root_ids},\n",
    "                                            materialization_version = mat_vers)\n",
    "    root_ids = [np.int64(i) for i in root_ids]\n",
    "    root_df = pd.DataFrame(root_ids, columns = ['pt_root_id'])\n",
    "    output_df = root_df.join(nuc_df.set_index('pt_root_id'), on='pt_root_id')\n",
    "    \n",
    "    return output_df\n",
    "\n",
    "def getNucNuc(nucleus_ids):\n",
    "    client = CAVEclient(\"flywire_fafb_production\")\n",
    "    mat_vers = max(client.materialize.get_versions())\n",
    "    nuc_df = client.materialize.query_table('nuclei_v1',\n",
    "                                            filter_in_dict={\"id\": nucleus_ids},\n",
    "                                            materialization_version = mat_vers)\n",
    "    return nuc_df\n",
    "\n",
    "# defines function to get presynaptic table entry using root id\n",
    "def getPreSyn(root_id):\n",
    "    client = CAVEclient(\"flywire_fafb_production\")\n",
    "    mat_vers = max(client.materialize.get_versions())\n",
    "    pre_syn_df = client.materialize.query_table('synapses_nt_v1', \n",
    "                                            filter_in_dict={\"pre_pt_root_id\":[root_id]})\n",
    "    return len(pre_syn_df)\n",
    "\n",
    "# defines function to get postsynaptic table entry using root id\n",
    "def getPostSyn(root_id):\n",
    "    client = CAVEclient(\"flywire_fafb_production\")\n",
    "    mat_vers = max(client.materialize.get_versions())\n",
    "    post_syn_df = client.materialize.query_table('synapses_nt_v1', \n",
    "                                            filter_in_dict={\"post_pt_root_id\":[root_id]})\n",
    "    return len(post_syn_df)\n",
    "\n",
    "# defines function to get edit data\n",
    "def getEdits(root_id):\n",
    "    client = CAVEclient(\"flywire_fafb_production\")\n",
    "    changes_dict = client.chunkedgraph.get_change_log(root_id)\n",
    "    return changes_dict   \n",
    "\n",
    "# defines function to build dataframe using root id list and 'options' (list of keywords based on checkboxes)\n",
    "def dfBuilderRoot(root_list,options):\n",
    "    root_list = [str(i) for i in root_list]             #ensures root ids are formatted as strings to avoid rounding#\n",
    "    df = pd.DataFrame(root_list, columns = ['Root ID']) #creates dataframe out of root_id list#\n",
    "\n",
    "    if 'nucs' in options:\n",
    "        nuc_df = getNucRoot(root_list)\n",
    "        df['Nucleus ID'] = nuc_df['id']\n",
    "        df['Nucleus Coordinates'] = nuc_df['pt_position'] #adds nucleus coordinates to df#\n",
    "#         df['Nucleus Volume'] = nuc_df['volume'] #TEMPORARILY REMOVED#\n",
    "\n",
    "    if 'syns' in options:\n",
    "        pre_list = []\n",
    "        post_list = []\n",
    "        total_list = []\n",
    "        for i in root_list:\n",
    "            try:\n",
    "                pre_list.append(getPreSyn(i))      #pulls synapse data#\n",
    "            except:\n",
    "                pre_list += ['n/a']\n",
    "            try:\n",
    "                post_list.append(getPostSyn(i))\n",
    "            except:\n",
    "                post_list += ['n/a']\n",
    "            try:\n",
    "                total_list.append(int(pre_list[-1] + post_list[-1]))\n",
    "            except:\n",
    "                total_list += ['n/a']\n",
    "                \n",
    "        df['Incoming Synapses'] = post_list\n",
    "        df['Outgoing Synapses'] = pre_list\n",
    "        df['Total Synapses'] = total_list\n",
    "    \n",
    "    if 'edits' in options: #CHANGE THIS TO TABULAR LOG#\n",
    "        split_list = []\n",
    "        merge_list = []\n",
    "        edit_list = []\n",
    "        for i in root_list:\n",
    "            try:\n",
    "                change_dict = getEdits(i)                         #pulls changelog#\n",
    "                split_list.append(change_dict['n_splits'])        #appends split list#\n",
    "                merge_list.append(change_dict['n_mergers'])       #appends merge list#\n",
    "                edit_list.append(split_list[-1] + merge_list[-1]) #appends edit list#\n",
    "            except:\n",
    "                split_list += ['n/a']\n",
    "                merge_list += ['n/a']\n",
    "                edit_list += ['n/a']\n",
    "        df['Splits'] = split_list\n",
    "        df['Mergers'] = merge_list\n",
    "        df['Edits'] = edit_list\n",
    "           \n",
    "    return df\n",
    "\n",
    "# defines function to build dataframe using root id list and 'options' (list of keywords based on checkboxes)\n",
    "def dfBuilderNuc(nuc_list,options):\n",
    "    \n",
    "    nuc_list = [int(i) for i in nuc_list]               #ensures nuc_list are ints#\n",
    "    nuc_df = getNucNuc(nuc_list)                        #creates nuc_df using nucleus ids#\n",
    "    root_list = nuc_df['pt_root_id'].to_list()          #converts pt_root_id column of nuc_df to list of root ids#\n",
    "    root_list = [str(i) for i in root_list]             #ensures root list are strings to avoid rounding#\n",
    "    df = pd.DataFrame(root_list, columns = ['Root ID']) #creates dataframe out of root_id list#\n",
    "\n",
    "    if 'nucs' in options:\n",
    "        df['Nucleus ID'] = nuc_list\n",
    "        df['Nucleus Coordinates'] = nuc_df['pt_position']\n",
    "#         df['Nucleus Volume'] = nuc_df['volume'] #TEMPORARILY REMOVED#\n",
    "\n",
    "    if 'syns' in options:\n",
    "        pre_list = []\n",
    "        post_list = []\n",
    "        total_list = []\n",
    "        for i in root_list:\n",
    "            try:\n",
    "                pre_list.append(getPreSyn(i))      #pulls synapse data#\n",
    "            except:\n",
    "                pre_list += ['n/a']\n",
    "            try:\n",
    "                post_list.append(getPostSyn(i))\n",
    "            except:\n",
    "                post_list += ['n/a']\n",
    "            try:\n",
    "                total_list.append(int(pre_list[-1] + post_list[-1]))\n",
    "            except:\n",
    "                total_list += ['n/a']\n",
    "                \n",
    "        df['Incoming Synapses'] = post_list\n",
    "        df['Outgoing Synapses'] = pre_list\n",
    "        df['Total Synapses'] = total_list\n",
    "    \n",
    "    if 'edits' in options: #CHANGE THIS TO TABULAR LOG#\n",
    "        split_list = []\n",
    "        merge_list = []\n",
    "        edit_list = []\n",
    "        for i in root_list:\n",
    "            try:\n",
    "                change_dict = getEdits(i)                         #pulls changelog#\n",
    "                split_list.append(change_dict['n_splits'])        #appends split list#\n",
    "                merge_list.append(change_dict['n_mergers'])       #appends merge list#\n",
    "                edit_list.append(split_list[-1] + merge_list[-1]) #appends edit list#\n",
    "            except:\n",
    "                split_list += ['n/a']\n",
    "                merge_list += ['n/a']\n",
    "                edit_list += ['n/a']\n",
    "        df['Splits'] = split_list\n",
    "        df['Mergers'] = merge_list\n",
    "        df['Edits'] = edit_list\n",
    "           \n",
    "    return df\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "44ace717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:8050/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [01/Nov/2021 17:07:55] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [01/Nov/2021 17:07:55] \"GET /_dash-layout HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [01/Nov/2021 17:07:55] \"GET /_dash-dependencies HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [01/Nov/2021 17:07:55] \"GET /_favicon.ico?v=2.0.0 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [01/Nov/2021 17:07:55] \"GET /_dash-component-suites/dash/dcc/async-dropdown.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [01/Nov/2021 17:07:55] \"GET /_dash-component-suites/dash/dash_table/async-highlight.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [01/Nov/2021 17:07:55] \"GET /_dash-component-suites/dash/dash_table/async-table.js HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# DASH APP #\n",
    "\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "# defines layout of various app elements (submission field, checkboxes, button, output table)#\n",
    "app.layout = html.Div([\n",
    "    dcc.Textarea(\n",
    "        id='message_text',\n",
    "        value='Choose lookup method from dropdown, input coordinates, select output parameters, and click \"Submit\" button.\\nID queries are limited to 20 entries, coordinate lookups must be done one at a time.\\nLookup takes ~2 seconds per entry.',\n",
    "        style={'width': '800px','resize': 'none'},\n",
    "        rows=3,\n",
    "        disabled=True,\n",
    "    ),\n",
    "    html.Div(dcc.Input(  #defines input field#\n",
    "        id='input_field', \n",
    "        type='text', \n",
    "        placeholder='ID Number',\n",
    "    )),\n",
    "    html.Br(\n",
    "    ),\n",
    "    dcc.Dropdown(\n",
    "        id='query_type',\n",
    "        options=[\n",
    "            {'label': 'Root ID', 'value': 'root_query'},\n",
    "            {'label': 'Nucleus ID', 'value': 'nuc_query'},\n",
    "            {'label': 'Coordinates (batch coordinate input not currently supported)', 'value': 'coord_query'},\n",
    "        ],\n",
    "        value='root_query',\n",
    "        style={'max-width': '500px'},\n",
    "    ),\n",
    "    html.Br(\n",
    "    ),\n",
    "    html.Div(dcc.Checklist(  #defines data selection checkboxes#\n",
    "        id='checkboxes',\n",
    "        options=[\n",
    "            {'label': 'Nucleus Info', 'value': 'nucs'},\n",
    "            {'label': 'Synapse Count', 'value': 'syns'},\n",
    "            {'label': 'Edits', 'value': 'edits'},\n",
    "        ],\n",
    "        labelStyle={'display': 'block'},\n",
    "        value=['nucs','syns','edits'],\n",
    "    )),\n",
    "    html.Br(\n",
    "    ),\n",
    "    html.Button(  #defines submission button#\n",
    "        'Submit', \n",
    "        id='submit_button', \n",
    "        n_clicks=0,\n",
    "    ),\n",
    "    html.Br(\n",
    "    ),\n",
    "    html.Div(dash_table.DataTable(  #defines output table#\n",
    "        id='table', \n",
    "        fill_width=False,  #sets column width to fit text instead of expanding to container width#\n",
    "        export_format=\"csv\",\n",
    "    ))\n",
    "])\n",
    "\n",
    "# defines callback that takes root ids and desired data selection on button click and generates table\n",
    "@app.callback(\n",
    "    Output('table','columns'),           #defines first output location as the 'columns' aspect of 'table'#\n",
    "    Output('table', 'data'),             #defines second output location as the 'data' aspect of 'table'#\n",
    "    Output('message_text','value'),      #defines second output location as the 'data' aspect of 'table'#\n",
    "    Input('submit_button', 'n_clicks'),  #defines trigger as button press (change in the state of the 'n_clicks' aspect of 'submit_button')# \n",
    "    State('query_type', 'value'),        #defines first input state as value of 'query_type'#\n",
    "    State('input_field', 'value'),       #defines second input state as the value of 'input_field'#\n",
    "    State('checkboxes','value'),         #defines third input state as the value of 'checkboxes'#\n",
    "    prevent_initial_call=True,\n",
    ")\n",
    "def update_output(n_clicks, query_method, ids, checked):\n",
    "    id_list = str(ids).split(\",\")                             #splits 'roots' string into list#\n",
    "    id_list = [int(x.strip(' ')) for x in id_list]            #strips spaces from root_list entries and converts to integers#\n",
    "    if len(id_list) <= 20:\n",
    "        if query_method == 'root_query':                          #creates dataframe for root id queries#\n",
    "            df = dfBuilderRoot(id_list, checked)\n",
    "        elif query_method == 'nuc_query':                         #creates dataframe for nucleus id queries#\n",
    "            df = dfBuilderNuc(id_list, checked)\n",
    "        elif query_method == 'coord_query':                       #creates dataframe for coordinate query#\n",
    "            derived_id = [coordsToRoot(id_list)]\n",
    "            df = dfBuilderRoot(derived_id, checked)\n",
    "        column_list = [{\"name\": i, \"id\": i} for i in df.columns]  #creates column list based on dataframe columns#\n",
    "        df_dict =  df.to_dict('records')                          #converts df to dictionary#\n",
    "        message_output = 'Choose lookup method from dropdown, input coordinates, select output parameters, and click \"Submit\" button.\\nID queries are limited to 20 entries, coordinate lookups must be done one at a time.'\n",
    "        output_list = [column_list,df_dict,message_output]        #combines df_dict and column_list into output list#\n",
    "        return output_list                                        #returns list of column names and data values#\n",
    "    else:\n",
    "        return [0,0,'Please limit each query to a maximum of 20 id numbers.']\n",
    "        \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd7ffe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BELOW THIS LINE IS TEST CODE#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afabf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCTION FOR NEUROTRANSMITTER DATA\n",
    "client = CAVEclient(\"flywire_fafb_production\")\n",
    "mat_vers = max(client.materialize.get_versions())\n",
    "pre_syn_df = client.materialize.query_table('synapses_nt_v1', \n",
    "                                        filter_in_dict={\"pre_pt_root_id\":[root_id]})\n",
    "return len(pre_syn_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1904234",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# TABULAR CHANGE LOG\n",
    "root_ids = [720575940629906060,720575940618617536,720575940618059861,720575940625091594,720575940612700450]\n",
    "client = CAVEclient(\"flywire_fafb_production\")\n",
    "df = pd.DataFrame()\n",
    "tab_log = client.chunkedgraph.get_tabular_change_log(root_ids)\n",
    "\n",
    "print(tab_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ab7f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -V\n",
    "\n",
    "# import caveclient\n",
    "\n",
    "# caveclient.__version__\n",
    "\n",
    "# client = caveclient.CAVEclient(\"flywire_fafb_production\")\n",
    "# root_ids = [720575940629906060,720575940618617536,720575940618059861,720575940625091594,720575940612700450]\n",
    "# tab_log = client.chunkedgraph.get_tabular_change_log(root_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7bc415",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#ARCHIVED ITERATIVE CHANGELOG FUNCTION#\n",
    "root_ids = [720575940629906060,720575940618617536,720575940618059861,720575940625091594,720575940612700450]\n",
    "client = CAVEclient(\"flywire_fafb_production\")\n",
    "df = pd.DataFrame()\n",
    "split_list = []\n",
    "merge_list = []\n",
    "edit_list = []\n",
    "for i in root_ids:\n",
    "    try:\n",
    "        change_dict = client.chunkedgraph.get_change_log(i)                         #pulls changelog#\n",
    "        split_list.append(change_dict['n_splits'])        #appends split list#\n",
    "        merge_list.append(change_dict['n_mergers'])       #appends merge list#\n",
    "        edit_list.append(split_list[-1] + merge_list[-1]) #appends edit list#\n",
    "    except:\n",
    "        split_list += ['n/a']\n",
    "        merge_list += ['n/a']\n",
    "        edit_list += ['n/a']\n",
    "df['Splits'] = split_list\n",
    "df['Mergers'] = merge_list\n",
    "df['Edits'] = edit_list\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4ed0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARCHIVED COORDINATE LOOKUP\n",
    "\n",
    "def coordsToRoot(coords):\n",
    "    # coordinates must be passed as list in [4,4,40] resolution #\n",
    "    import cloudvolume\n",
    "    from cloudvolume import CloudVolume\n",
    "    from caveclient import CAVEclient\n",
    "\n",
    "    # sets client #\n",
    "    client = CAVEclient(\"flywire_fafb_production\")\n",
    "\n",
    "    # sets cloud volume #\n",
    "    cv = cloudvolume.CloudVolume(\"graphene://https://prod.flywire-daf.com/segmentation/1.0/fly_v31\", use_https=True)\n",
    "\n",
    "    # determines resolution of volume #\n",
    "    res = cv.resolution\n",
    "\n",
    "    # converts coordinates using volume resolution #\n",
    "    cv_xyz = [int(coords[0]/(res[0]/4)),int(coords[1]/(res[1]/4)),int(coords[2]/(res[2]/40))]\n",
    "\n",
    "    # sets point by passing converted coordinates into 'download_point' method #\n",
    "    point = int(cv.download_point(cv_xyz, size=1))\n",
    "\n",
    "    # should give result of 82686985730511836 #\n",
    "    print(point)\n",
    "\n",
    "    # looks up root id for that supervoxel using chunkedgraph #\n",
    "    root_result = client.chunkedgraph.get_root_id(supervoxel_id=point)\n",
    "\n",
    "    # should give result of 82686985730511836 #\n",
    "    return root_result\n",
    "\n",
    "coordsToRoot([175196, 61786, 3754])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
