{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695b63ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTATIONS#\n",
    "\n",
    "# core importations\n",
    "from caveclient import CAVEclient\n",
    "import cloudvolume\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import json\n",
    "from nglui.statebuilder import *\n",
    "from annotationframeworkclient import FrameworkClient\n",
    "\n",
    "# dash importations\n",
    "import dash\n",
    "from dash import Dash, dcc, html, Input, Output, State, dash_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4f1b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCTIONS#\n",
    "\n",
    "def buildLink(query_id,up_ids,down_ids,cleft_thresh,nucleus,cb=False):\n",
    "\n",
    "    # checks for colorblind option, sets color #\n",
    "    if cb == True:\n",
    "        up_color = '#ffffff' # white #\n",
    "        query_color = '#999999' # 40% grey #\n",
    "        down_color = '#323232' # 80% grey #\n",
    "    else:\n",
    "        up_color = '#00ffff' # cyan #\n",
    "        query_color = '#ff00ff' # magenta #\n",
    "        down_color = '#ffff00' # yellow #\n",
    "\n",
    "    # builds id and color lists #\n",
    "    id_list = query_id + up_ids + down_ids\n",
    "    color_list = [query_color] + ([up_color]*len(up_ids)) + ([down_color]*len(down_ids))\n",
    "\n",
    "    # sets Framework client using flywire production datastack #\n",
    "    Fclient = FrameworkClient('flywire_fafb_production')\n",
    "\n",
    "    # sets configuration for EM layer #\n",
    "    img = ImageLayerConfig(Fclient.info.image_source())\n",
    "\n",
    "    # sets configuration for segmentation layer #\n",
    "    seg = SegmentationLayerConfig(\n",
    "        name = 'seg',\n",
    "        source = Fclient.info.segmentation_source(),\n",
    "        fixed_ids = id_list,\n",
    "        fixed_id_colors = color_list,\n",
    "        view_kws = {'alpha_3d': 0.8},\n",
    "    )\n",
    "\n",
    "    # sets CAVE client #\n",
    "    Cclient = CAVEclient('flywire_fafb_production')\n",
    "        \n",
    "    # gets current materialization version #\n",
    "    mat_vers = max(Cclient.materialize.get_versions())\n",
    "\n",
    "    # generates synapse dfs using up- & downstream ids #\n",
    "    up_df = Cclient.materialize.query_table(\n",
    "        'synapses_nt_v1',\n",
    "        filter_in_dict={\n",
    "            'pre_pt_root_id':up_ids,\n",
    "            \"post_pt_root_id\":query_id,\n",
    "        },\n",
    "        materialization_version = mat_vers,\n",
    "    )\n",
    "    down_df = Cclient.materialize.query_table(\n",
    "        'synapses_nt_v1',\n",
    "        filter_in_dict={\n",
    "            'pre_pt_root_id':query_id,\n",
    "            \"post_pt_root_id\":down_ids,\n",
    "        },\n",
    "        materialization_version = mat_vers,\n",
    "    )\n",
    "\n",
    "    # combines synapse dfs #\n",
    "    synapses_df = up_df.append(down_df, ignore_index = True)\n",
    "\n",
    "    # removes synapses below cleft threshold #\n",
    "    synapses_df = synapses_df[synapses_df['cleft_score'] >= cleft_thresh].reset_index(drop = True)\n",
    "\n",
    "    # makes truncated df of pre & post coords #\n",
    "    coords_df = pd.DataFrame({\n",
    "        'pre':[[x[0]/4,x[1]/4,x[2]/40] for x in synapses_df['pre_pt_position']],\n",
    "        'post':[[x[0]/4,x[1]/4,x[2]/40] for x in synapses_df['post_pt_position']],\n",
    "    })\n",
    "\n",
    "    # defines configuration for line annotations #\n",
    "    lines = LineMapper(\n",
    "        point_column_a = 'pre',\n",
    "        point_column_b = 'post',\n",
    "        # description_column = '', # optional description #\n",
    "    )\n",
    "\n",
    "    # defines configuration for annotation layer #\n",
    "    anno = AnnotationLayerConfig(\n",
    "        name='synapses',\n",
    "        mapping_rules=lines,\n",
    "    )\n",
    "\n",
    "    # sets view to nucelus of query cell, defaults to center of dataset if no input #\n",
    "    \n",
    "    if int(nucleus[0]) > 0 :\n",
    "        view_options = {\n",
    "            'position':nucleus,\n",
    "            'zoom_3d':2000,\n",
    "        }\n",
    "    else:\n",
    "        view_options = {\n",
    "            'position':[119412, 62016, 3539],\n",
    "            'zoom_3d':10000,\n",
    "        }\n",
    "\n",
    "    # defines 'sb' by passing in rules for img, seg, and anno layers\n",
    "    sb = StateBuilder(\n",
    "        [img, seg, anno],\n",
    "        view_kws = view_options,\n",
    "    )\n",
    "\n",
    "    # renders state as json and converts dumped json produced by render_state into \n",
    "    # non-dumped version using json.loads()\n",
    "    state_json = json.loads(sb.render_state(coords_df, \n",
    "                                            return_as = 'json'))\n",
    "\n",
    "    # feeds state_json into state uploader to set the value of 'new_id'\n",
    "    new_id = Fclient.state.upload_state_json(state_json)\n",
    "\n",
    "    # defines url using url builder, passing in the new_id and the ngl url\n",
    "    url = Fclient.state.build_neuroglancer_url(state_id = new_id, \n",
    "                                            ngl_url ='https://ngl.flywire.ai/')\n",
    "                                            \n",
    "    return url\n",
    "\n",
    "# defines function to validate constructed synapse data #\n",
    "def checkValid(up_df, down_df, incoming_df, outgoing_df):\n",
    "\n",
    "    # sets counter #\n",
    "    counter = 0\n",
    "\n",
    "    # validates upstream partners #\n",
    "    for x in up_df.index:\n",
    "        built_con = up_df.loc[x,'Connections']\n",
    "        quer_con = str(\n",
    "            list(incoming_df['pre_pt_root_id'].astype(str)).count(\n",
    "                up_df.loc[x,'Upstream Partner ID']))\n",
    "        \n",
    "        if(\n",
    "            built_con == quer_con\n",
    "            # round(np.mean(out_df['gaba']),3) == row_df.loc[0,'Gaba Avg']\n",
    "            # round(np.mean(out_df['ach']),3) == row_df.loc[0,'Ach Avg'] and\n",
    "            # round(np.mean(out_df['glut']),3) == row_df.loc[0,'Glut Avg'] and\n",
    "            # round(np.mean(out_df['oct']),3) == row_df.loc[0,'Oct Avg'] and\n",
    "            # round(np.mean(out_df['ser']),3) == row_df.loc[0,'Ser Avg'] and\n",
    "            # round(np.mean(out_df['da']),3) == row_df.loc[0,'Da Avg']\n",
    "        ):\n",
    "            counter += 1\n",
    "        else:\n",
    "            failed = counter + ' items validated. Upstream data false for partner '+ up_df.loc[x,'Upstream Partner ID'] + \\\n",
    "                    '. Built count = ' + built_con + '. Query count = ' + quer_con\n",
    "            return failed\n",
    "    \n",
    "    # validates downstream partners #\n",
    "    for x in down_df.index:\n",
    "        built_con = down_df.loc[x,'Connections']\n",
    "        quer_con = str(\n",
    "            list(outgoing_df['post_pt_root_id'].astype(str)).count(\n",
    "                down_df.loc[x,'Downstream Partner ID']))\n",
    "        \n",
    "        if(\n",
    "            built_con == quer_con\n",
    "        ):\n",
    "            counter += 1\n",
    "        else:\n",
    "            failed = counter + ' items validated. Downstream data false for partner '+ down_df.loc[x,'Downstream Partner ID'] + \\\n",
    "                    '. Built count = ' + built_con + '. Query count = ' + quer_con\n",
    "            return failed\n",
    "    \n",
    "    return 'All ' + str(counter) + ' items have been validated.'\n",
    "\n",
    "# defines function to convert nm coordinates into FlyWire-usable 4,4,40 #\n",
    "def coordConvert(coords):\n",
    "    x = coords\n",
    "    x[0] /= 4\n",
    "    x[1] /= 4\n",
    "    x[2] /= 40\n",
    "    x = [int(str(i).strip()) for i in x]\n",
    "    return x\n",
    "\n",
    "# defines function to convert list of x,y,z coordinates in [4,4,40] resolution to root id #\n",
    "def coordsToRoot(coords):\n",
    "    \n",
    "    # converts coordinates to ints #\n",
    "    coords = list(map(int,coords))\n",
    "\n",
    "    # sets client #\n",
    "    client = CAVEclient(\"flywire_fafb_production\")\n",
    "\n",
    "    # sets cloud volume #\n",
    "    cv = cloudvolume.CloudVolume(\"graphene://https://prod.flywire-daf.com/segmentation/1.0/fly_v31\", use_https=True)\n",
    "\n",
    "    # determines resolution of volume #\n",
    "    res = cv.resolution\n",
    "\n",
    "    # converts coordinates using volume resolution #\n",
    "    cv_xyz = [\n",
    "        int(coords[0]/(res[0]/4)),\n",
    "        int(coords[1]/(res[1]/4)),\n",
    "        int(coords[2]/(res[2]/40))\n",
    "        ]\n",
    "\n",
    "    # sets point by passing converted coordinates into 'download_point' method #\n",
    "    point = int(cv.download_point(cv_xyz, size=1))\n",
    "\n",
    "    # looks up root id for that supervoxel using chunkedgraph, converts to string #\n",
    "    root_result = str(client.chunkedgraph.get_root_id(supervoxel_id=point))\n",
    "\n",
    "    return root_result\n",
    "\n",
    "# defines function to build dataframe using list-formatted root/nuc id or coords #\n",
    "def dfBuilder(input_list, cleft_thresh, validate):\n",
    "\n",
    "    # if coordinates detected, converts to root #\n",
    "    if len(input_list) == 3:\n",
    "        input_list = [coordsToRoot(input_list)]\n",
    "\n",
    "    # uses root or nuc id to build nuc df #\n",
    "    nuc_df = getNuc(input_list)\n",
    "\n",
    "    # uses root id to build synapse dataframes #\n",
    "    syn_sum_df, up_df, down_df, val_status = getSyn(\n",
    "        [str(nuc_df.loc[0,'Root ID'])], \n",
    "        cleft_thresh,\n",
    "        validate,\n",
    "        )\n",
    "\n",
    "    # joins synapse summary to nucleus df to create summary df\n",
    "    sum_df = nuc_df.join(\n",
    "        syn_sum_df.set_index('Root ID'), \n",
    "        on='Root ID'\n",
    "        )\n",
    "    \n",
    "    #returns output dataframes#\n",
    "    return [sum_df, up_df, down_df, val_status]\n",
    "\n",
    "# defines function for querying nucleus table using list of root or nuc ids #\n",
    "def getNuc(id_list):\n",
    "    \n",
    "    # sets client #\n",
    "    client = CAVEclient(\"flywire_fafb_production\")\n",
    "    \n",
    "    # gets current materialization version #\n",
    "    mat_vers = max(client.materialize.get_versions())\n",
    "    \n",
    "    # pulls nucleus table results based on query type #\n",
    "    if len(id_list[0]) == 7:\n",
    "        nuc_df = client.materialize.query_table(\n",
    "            'nuclei_v1',\n",
    "            filter_in_dict={\"id\": id_list},\n",
    "            materialization_version = mat_vers\n",
    "            )\n",
    "    elif len(id_list[0]) == 18:\n",
    "        nuc_df = client.materialize.query_table(\n",
    "            'nuclei_v1',\n",
    "            filter_in_dict={\"pt_root_id\": id_list},\n",
    "            materialization_version = mat_vers\n",
    "            )\n",
    "\n",
    "    # converts nucleus coordinates from n to 4x4x40 resolution #    \n",
    "    nuc_df['pt_position'] = [coordConvert(i) for i in nuc_df['pt_position']]\n",
    "    \n",
    "    # creates output dataframe using root id, nuc id, and nuc coords from table to keep alignment #\n",
    "    out_df = pd.DataFrame({\n",
    "        'Root ID':list(nuc_df['pt_root_id']),\n",
    "        'Nucleus ID':list(nuc_df['id']),\n",
    "        'Nucleus Coordinates':list(nuc_df['pt_position'])\n",
    "        })\n",
    "        \n",
    "    return out_df.astype(str)\n",
    "\n",
    "# defines function to get synapse info using root ID#\n",
    "def getSyn(root_id, cleft_thresh=0, validate=False):\n",
    "\n",
    "    #sets client#\n",
    "    client = CAVEclient(\"flywire_fafb_production\")\n",
    "    \n",
    "    #gets current materialization version#\n",
    "    mat_vers = max(client.materialize.get_versions())\n",
    "    \n",
    "    #makes dfs of pre- (outgoing) and post- (incoming) synapses #\n",
    "    outgoing_syn_df = client.materialize.query_table(\n",
    "        'synapses_nt_v1',\n",
    "        filter_in_dict={\"pre_pt_root_id\":root_id},\n",
    "        materialization_version = mat_vers\n",
    "        )\n",
    "    incoming_syn_df = client.materialize.query_table(\n",
    "        'synapses_nt_v1',\n",
    "        filter_in_dict={\"post_pt_root_id\":root_id},\n",
    "        materialization_version = mat_vers\n",
    "        )\n",
    "\n",
    "    # removes synapses below cleft threshold, 0-roots, and autapses #\n",
    "    outgoing_syn_df = outgoing_syn_df[outgoing_syn_df['cleft_score'] >= cleft_thresh].reset_index(drop = True)\n",
    "    outgoing_syn_df = outgoing_syn_df[outgoing_syn_df[\"pre_pt_root_id\"] != outgoing_syn_df[\"post_pt_root_id\"]].reset_index(drop = True)\n",
    "    outgoing_syn_df = outgoing_syn_df[outgoing_syn_df[\"post_pt_root_id\"] != 0].reset_index(drop = True)\n",
    "    incoming_syn_df = incoming_syn_df[incoming_syn_df['cleft_score'] >= cleft_thresh].reset_index(drop = True)\n",
    "    incoming_syn_df = incoming_syn_df[incoming_syn_df[\"pre_pt_root_id\"] != incoming_syn_df[\"post_pt_root_id\"]].reset_index(drop = True)\n",
    "    incoming_syn_df = incoming_syn_df[incoming_syn_df[\"post_pt_root_id\"] != 0].reset_index(drop = True)\n",
    "\n",
    "    # calculates total synapses #\n",
    "    in_count = len(incoming_syn_df)\n",
    "    out_count = len(outgoing_syn_df)\n",
    "    \n",
    "    # gets lists of pre and post synaptic partners #\n",
    "    downstream_partners = list(outgoing_syn_df.drop_duplicates(subset = 'post_pt_root_id')['post_pt_root_id'])\n",
    "    upstream_partners = list(incoming_syn_df.drop_duplicates(subset = 'pre_pt_root_id')['pre_pt_root_id'])\n",
    "\n",
    "    # calculates number of upstream and downstream partners #\n",
    "    up_count = len(upstream_partners)\n",
    "    down_count = len(downstream_partners)\n",
    "\n",
    "    # builds output dataframes #\n",
    "    summary_df = pd.DataFrame({\n",
    "        'Root ID':root_id,\n",
    "        'Incoming':in_count,\n",
    "        'Outgoing':out_count,\n",
    "        'Upstream Partners':up_count,\n",
    "        'Downstream Partners':down_count\n",
    "        })\n",
    "    up_df = pd.DataFrame({'Partner ID':upstream_partners})\n",
    "    down_df = pd.DataFrame({'Partner ID':downstream_partners})\n",
    "\n",
    "    # adds number of connections between input neuron and partners #\n",
    "    up_df['Connections'] = [list(incoming_syn_df['pre_pt_root_id']).count(x) for x in upstream_partners]\n",
    "    down_df['Connections'] = [list(outgoing_syn_df['post_pt_root_id']).count(x) for x in downstream_partners]\n",
    "\n",
    "    # adds neurotransmitter averages for each partner #\n",
    "    up_df = up_df.join(\n",
    "        ntMeans(\n",
    "            upstream_partners,\n",
    "            incoming_syn_df,\n",
    "            'pre_pt_root_id'\n",
    "            ).set_index('Partner ID'), \n",
    "        on='Partner ID'\n",
    "        )\n",
    "    down_df = down_df.join(\n",
    "        ntMeans(\n",
    "            downstream_partners,\n",
    "            outgoing_syn_df,\n",
    "            'post_pt_root_id'\n",
    "            ).set_index('Partner ID'), \n",
    "        on='Partner ID'\n",
    "        )\n",
    "\n",
    "    # renames partner id columns to up/downstream #\n",
    "    up_df = up_df.rename(columns={\"Partner ID\": \"Upstream Partner ID\"})\n",
    "    down_df = down_df.rename(columns={\"Partner ID\": \"Downstream Partner ID\"})\n",
    "\n",
    "    # sorts by number of connetions #\n",
    "    up_df = up_df.astype({'Connections':int}).sort_values(by='Connections', ascending=False)\n",
    "    down_df = down_df.astype({'Connections':int}).sort_values(by='Connections', ascending=False)\n",
    "\n",
    "    # converts all data to strings #\n",
    "    summary_df = summary_df.astype(str)\n",
    "    up_df = up_df.astype(str)\n",
    "    down_df = down_df.astype(str)\n",
    "\n",
    "    # runs data validation if input variable is set to True #\n",
    "    if validate == True:\n",
    "        val_out = checkValid(up_df, down_df, incoming_syn_df, outgoing_syn_df)\n",
    "        return [summary_df,up_df,down_df, val_out]\n",
    "    else:\n",
    "        return [summary_df,up_df,down_df,'Data not validated']\n",
    "\n",
    "# defines function to generate violin plot of neurotransmitters when fed root id and cleft threshold #\n",
    "def makeViolin(root_id,cleft_thresh):\n",
    "\n",
    "    # sets client #\n",
    "    client = CAVEclient(\"flywire_fafb_production\")\n",
    "    \n",
    "    # gets current materialization version #\n",
    "    mat_vers = max(client.materialize.get_versions())\n",
    "    \n",
    "    # builds dfs using up and down ids, mat vers #\n",
    "    pre_df = client.materialize.query_table(\n",
    "        'synapses_nt_v1',\n",
    "        filter_in_dict={\n",
    "            'pre_pt_root_id':[root_id],\n",
    "            },\n",
    "        materialization_version = mat_vers\n",
    "        )\n",
    "    post_df = client.materialize.query_table(\n",
    "        'synapses_nt_v1',\n",
    "        filter_in_dict={\n",
    "            'post_pt_root_id':[root_id],\n",
    "            },\n",
    "        materialization_version = mat_vers\n",
    "        )\n",
    "\n",
    "    # removes synapses below cleft threshold, 0-roots, and autapses #\n",
    "    pre_df = pre_df[pre_df['cleft_score'] >= cleft_thresh].reset_index(drop = True)\n",
    "    pre_df = pre_df[pre_df['pre_pt_root_id'] != pre_df[\"post_pt_root_id\"]].reset_index(drop = True)\n",
    "    pre_df = pre_df[pre_df['post_pt_root_id'] != 0].reset_index(drop = True)\n",
    "    post_df = post_df[post_df['cleft_score'] >= cleft_thresh].reset_index(drop = True)\n",
    "    post_df = post_df[post_df['pre_pt_root_id'] != post_df[\"post_pt_root_id\"]].reset_index(drop = True)\n",
    "    post_df = post_df[post_df['post_pt_root_id'] != 0].reset_index(drop = True)\n",
    "\n",
    "    # rounds data to 2 decimal places #\n",
    "    pre_df = pre_df.round(2)\n",
    "    post_df = post_df.round(2)\n",
    "\n",
    "    # creates blank figures #\n",
    "    pre_fig = go.Figure()\n",
    "    post_fig = go.Figure()\n",
    "\n",
    "    # adds line data #\n",
    "    pre_fig.add_trace(go.Violin(y=list(pre_df['gaba']), name='Gaba'))\n",
    "    pre_fig.add_trace(go.Violin(y=list(pre_df['ach']), name='Ach'))\n",
    "    pre_fig.add_trace(go.Violin(y=list(pre_df['glut']), name='Glut'))\n",
    "    pre_fig.add_trace(go.Violin(y=list(pre_df['oct']), name='Oct'))\n",
    "    pre_fig.add_trace(go.Violin(y=list(pre_df['ser']), name='Ser'))\n",
    "    pre_fig.add_trace(go.Violin(y=list(pre_df['da']), name='Da'))\n",
    "    post_fig.add_trace(go.Violin(y=list(post_df['gaba']), name='Gaba'))\n",
    "    post_fig.add_trace(go.Violin(y=list(post_df['ach']), name='Ach'))\n",
    "    post_fig.add_trace(go.Violin(y=list(post_df['glut']), name='Glut'))\n",
    "    post_fig.add_trace(go.Violin(y=list(post_df['oct']), name='Oct'))\n",
    "    post_fig.add_trace(go.Violin(y=list(post_df['ser']), name='Ser'))\n",
    "    post_fig.add_trace(go.Violin(y=list(post_df['da']), name='Da'))\n",
    "    \n",
    "    # hides points #\n",
    "    pre_fig.update_traces(points=False)\n",
    "    post_fig.update_traces(points=False)\n",
    "\n",
    "    # fixes layout to minimize padding and fit both on one line #\n",
    "    post_fig.update_layout(\n",
    "        title = \"Incoming Synapse NT Averages\",\n",
    "        margin = {'l':5,'r':5,'t':25,'b':5},\n",
    "        width = 400,\n",
    "        height = 200,\n",
    "    )\n",
    "    pre_fig.update_layout(\n",
    "        title = \"Outgoing Synapse NT Averages\",\n",
    "        margin = {'l':5,'r':5,'t':25,'b':5},\n",
    "        width = 400,\n",
    "        height = 200,\n",
    "    )\n",
    "\n",
    "    return [pre_fig,post_fig]\n",
    "\n",
    "# defines function to create df of nt averages #\n",
    "def ntMeans(ids,df,col_name):\n",
    "\n",
    "    # makes blank output dataframe #\n",
    "    out_df = pd.DataFrame()\n",
    "    \n",
    "    # iterates through partner ids #\n",
    "    for x in ids:\n",
    "\n",
    "        # filters main df to only include entries for partner #\n",
    "        partner_df = (df.loc[df[col_name] == x]).reset_index(drop = True)\n",
    "\n",
    "        # creates row dataframe and fills with nt avgs#\n",
    "        row_df = pd.DataFrame({'Partner ID':[x]})\n",
    "        row_df['Gaba Avg'] = [round(partner_df['gaba'].mean(),3)]\n",
    "        row_df['Ach Avg'] = [round(partner_df['ach'].mean(),3)]\n",
    "        row_df['Glut Avg'] = [round(partner_df['glut'].mean(),3)]\n",
    "        row_df['Oct Avg'] = [round(partner_df['oct'].mean(),3)]\n",
    "        row_df['Ser Avg'] = [round(partner_df['ser'].mean(),3)]\n",
    "        row_df['Da Avg'] = [round(partner_df['da'].mean(),3)]\n",
    "\n",
    "        # adds row df to output df #\n",
    "        out_df = out_df.append(row_df).reset_index(drop = True)\n",
    "\n",
    "    return out_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7f65b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DASH APP #\n",
    "\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "# defines layout of various app elements (submission field, checkboxes, button, output table)#\n",
    "app.layout = html.Div([\n",
    "    \n",
    "    #defines text area for instructions and feedback#\n",
    "    dcc.Textarea(\n",
    "        id='message_text',\n",
    "        value='Input root/nuc ID or coordinates \\nand click \"Submit\" button.\\n'\\\n",
    "            'Only one entry at a time.',\n",
    "        style={'width': '250px','resize': 'none'},\n",
    "        rows=3,\n",
    "        disabled=True,\n",
    "    ),\n",
    "    \n",
    "    #defines input field#\n",
    "    html.Div(dcc.Input(  \n",
    "        id='input_field', \n",
    "        type='text', \n",
    "        placeholder='Root/Nuc ID or Coordinates',\n",
    "    )),\n",
    "    \n",
    "    html.Br(\n",
    "    ),\n",
    "\n",
    "    # defines message explaining cleft score field #\n",
    "    dcc.Textarea(\n",
    "        id='cleft_message_text',\n",
    "        value='Cleft score threshold for synapses:',\n",
    "        style={'width': '260px','resize': 'none'},\n",
    "        rows=1,\n",
    "        disabled=True,\n",
    "    ),\n",
    "\n",
    "    # defines input field for cleft score threshold #\n",
    "    html.Div(dcc.Input(  \n",
    "        id='cleft_thresh_field', \n",
    "        type='number',\n",
    "        value=50,\n",
    "        \n",
    "    )),\n",
    "\n",
    "    html.Br(\n",
    "    ),\n",
    "\n",
    "    # defines validation checkbox #\n",
    "    html.Div(dcc.Checklist(  \n",
    "        id='val_check',\n",
    "        options=[{'label': 'Data Validation','value': True}],\n",
    "        labelStyle={'display': 'block'},\n",
    "    )),\n",
    "\n",
    "    #defines submission button#\n",
    "    html.Button(  \n",
    "        'Submit', \n",
    "        id='submit_button', \n",
    "        n_clicks=0,\n",
    "        style={'margin-top': '15px','margin-bottom': '15px'}\n",
    "    ),\n",
    "    \n",
    "    html.Br(\n",
    "    ),\n",
    "    \n",
    "    # defines neurotransmitter plot display div #\n",
    "    html.Div(\n",
    "        id = 'graph_div',\n",
    "        children=[],\n",
    "        style={'display': 'inline-block'}\n",
    "    ),\n",
    "\n",
    "    html.Br(\n",
    "    ),\n",
    "\n",
    "    # defines link generation button #\n",
    "    html.Div(\n",
    "        children=[\n",
    "            html.Button(  \n",
    "                'Clear Partner Selections', \n",
    "                id='clear_button', \n",
    "                n_clicks=0,\n",
    "                style={'margin-top': '15px','margin-bottom': '15px'},\n",
    "            ),\n",
    "            html.Button(  \n",
    "                'Generate NG Link Using Selected Partners', \n",
    "                id='link_button', \n",
    "                n_clicks=0,\n",
    "                style={\n",
    "                    'margin-top': '15px',\n",
    "                    'margin-bottom': '15px',\n",
    "                    'margin-right':'15px',\n",
    "                    'margin-left':'15px'\n",
    "                },\n",
    "            ),\n",
    "            dcc.Link(\n",
    "                href='',\n",
    "                id='ng_link',\n",
    "                style={'margin-top': '15px','margin-bottom': '15px'},\n",
    "            ),\n",
    "        ],\n",
    "        style={'display': 'inline-block'},\n",
    "    ),\n",
    "\n",
    "    # defines summary table#\n",
    "    html.Div(dash_table.DataTable(  \n",
    "        id='summary_table', \n",
    "        fill_width=False,\n",
    "        export_format=\"csv\",\n",
    "    )),\n",
    "\n",
    "    html.Br(\n",
    "    ),\n",
    "\n",
    "        # UNFINISHED ATTEMPT TO PUT BOTH TABLES ON SAME LINE #\n",
    "    # html.Div(\n",
    "    #     children=[\n",
    "    #         html.Div(\n",
    "    #             dash_table.DataTable(  \n",
    "    #                 id='incoming_table', \n",
    "    #                 fill_width=False, \n",
    "    #                 export_format=\"csv\",\n",
    "    #                 style_table={'width':'45%'},\n",
    "    #             ),\n",
    "    #             style = {'display':'inline-block'},\n",
    "    #         ),\n",
    "    #         html.Div(\n",
    "    #             dash_table.DataTable(  \n",
    "    #                 id='outgoing_table', \n",
    "    #                 fill_width=False, \n",
    "    #                 export_format=\"csv\",\n",
    "    #                 style_table={'width':'45%'},\n",
    "    #             ),\n",
    "    #             style = {'display':'inline-block'},\n",
    "    #         ),\n",
    "    #     ],\n",
    "    # ),\n",
    "\n",
    "    #defines incoming table#\n",
    "    html.Div(dash_table.DataTable(  \n",
    "        id='incoming_table', \n",
    "        export_format=\"csv\",\n",
    "        style_table={'height': '180px', 'overflowY': 'auto'},\n",
    "        page_action='none',\n",
    "        fixed_rows={'headers': True},\n",
    "        style_cell={'width': 160},\n",
    "        # active_cell={'row':0,'column':0}\n",
    "    )),\n",
    "\n",
    "    html.Br(\n",
    "    ),\n",
    "    \n",
    "    #defines outgoing table#\n",
    "    html.Div(dash_table.DataTable(  \n",
    "        id='outgoing_table', \n",
    "        export_format=\"csv\",\n",
    "        style_table={'height': '180px', 'overflowY': 'auto'},\n",
    "        page_action='none',\n",
    "        fixed_rows={'headers': True},\n",
    "        style_cell={'width': 160},\n",
    "        # active_cell={'row':0,'column':0}\n",
    "    ))\n",
    "])\n",
    "\n",
    "#defines callback that takes root ids and desired data selection on button click and generates table#\n",
    "@app.callback(\n",
    "    Output('summary_table','columns'),\n",
    "    Output('summary_table', 'data'),\n",
    "    Output('graph_div','children'),\n",
    "    Output('incoming_table','columns'),\n",
    "    Output('incoming_table', 'data'),\n",
    "    Output('outgoing_table','columns'),\n",
    "    Output('outgoing_table', 'data'),\n",
    "    Output('message_text','value'),\n",
    "    Input('submit_button', 'n_clicks'),  #defines trigger as button press (change in the state of the 'n_clicks' aspect of 'submit_button')# \n",
    "    State('input_field', 'value'),\n",
    "    State('cleft_thresh_field','value'),\n",
    "    State('val_check','value'),\n",
    "    prevent_initial_call=True,           #prevents function from being called on page load (prior to input)#\n",
    ")\n",
    "def update_output(n_clicks, input_list, cleft_thresh,val_choice):\n",
    "\n",
    "    # splits 'ids' string into list #\n",
    "    input_list = str(input_list).split(\",\")\n",
    "    \n",
    "    # strips spaces from id_list entries and converts to integers #\n",
    "    input_list = [str(x.strip(' ')) for x in input_list]\n",
    "\n",
    "    # builds output if 1-item threshold isn't exceeded #\n",
    "    if len(input_list) == 1 or len(input_list) == 3 and len(input_list[0]) != len(input_list[2]):\n",
    "\n",
    "        # sets data validation input #\n",
    "        if val_choice == True:\n",
    "            val_in = True\n",
    "        else:\n",
    "            val_in = False\n",
    "\n",
    "        # sets dataframes by passing id/coords into dfBuilder function #\n",
    "        sum_df, up_df, down_df , val_status = dfBuilder(input_list, cleft_thresh, val_in)\n",
    "\n",
    "        # creates column lists based on dataframe columns #\n",
    "        sum_column_list = [{\"name\": i, \"id\": i} for i in sum_df.columns]\n",
    "        up_column_list = [{\"name\": i, \"id\": i} for i in up_df.columns]\n",
    "        down_column_list = [{\"name\": i, \"id\": i} for i in down_df.columns]\n",
    "        \n",
    "        # makes dictionaries from dataframes #\n",
    "        sum_dict =  sum_df.to_dict('records')\n",
    "        up_dict =  up_df.to_dict('records')\n",
    "        down_dict =  down_df.to_dict('records')\n",
    "\n",
    "        # changes message to reflect validation status #\n",
    "        message_output = val_status\n",
    "        \n",
    "        # sets nt figures using makeViolin #\n",
    "        out_fig, in_fig = makeViolin(sum_df.loc[0,'Root ID'],cleft_thresh)\n",
    "\n",
    "        # builds list of figures to pass to children of graph_div #\n",
    "        fig_list = [   \n",
    "            html.Div(\n",
    "                dcc.Graph(\n",
    "                    id = 'incoming_figure',\n",
    "                    figure = in_fig,\n",
    "                ),\n",
    "                style = {'display':'inline-block'},\n",
    "            ),\n",
    "            html.Div(\n",
    "                dcc.Graph(\n",
    "                    id = 'outgoing_figure',\n",
    "                    figure = out_fig,\n",
    "                ),\n",
    "                style = {'display':'inline-block'},\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        #returns list of column names, data values, and message text#\n",
    "        return [\n",
    "            sum_column_list, \n",
    "            sum_dict,\n",
    "            fig_list, \n",
    "            up_column_list, \n",
    "            up_dict, \n",
    "            down_column_list, \n",
    "            down_dict, \n",
    "            message_output\n",
    "        ]               \n",
    "    \n",
    "    # returns error message if 1-item threshold is exceeded #\n",
    "    else:\n",
    "        return [0,0,0,0,0,0,'Please limit each query to one entry.']\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('ng_link','href'),\n",
    "    Input('link_button','n_clicks'),\n",
    "    State('incoming_table','active_cell'),\n",
    "    State('outgoing_table','active_cell'),\n",
    "    State('summary_table','data'),\n",
    "    State('incoming_table','data'),\n",
    "    State('outgoing_table','data'),\n",
    "    State('cleft_thresh_field','value'),\n",
    "    prevent_initial_call=True, \n",
    ")\n",
    "def makeLink(n_clicks,up_id,down_id,query_data,up_data,down_data,cleft_thresh):\n",
    "    \n",
    "    query_out = query_data[0]['Root ID']\n",
    "    \n",
    "    if up_id is None:\n",
    "        up_out = 0\n",
    "    else:\n",
    "        up_out = up_data[up_id['row']]['Upstream Partner ID']\n",
    "    if down_id is None:\n",
    "        down_out = 0\n",
    "    else:\n",
    "        down_out = down_data[down_id['row']]['Downstream Partner ID']\n",
    "\n",
    "    nuc = query_data[0]['Nucleus Coordinates'][1:-1].split(',')\n",
    "\n",
    "    out_url = buildLink([query_out],[up_out],[down_out],cleft_thresh,nuc)\n",
    "\n",
    "    return out_url\n",
    "\n",
    "@app.callback(\n",
    "    Output('incoming_table','active_cell'),\n",
    "    Output('outgoing_table','active_cell'),\n",
    "    Output('incoming_table','selected_cells'),\n",
    "    Output('outgoing_table','selected_cells'),\n",
    "    Input('clear_button','n_clicks'),\n",
    "    prevent_initial_call=True, \n",
    ")\n",
    "def clearSelected(n_clicks):\n",
    "    return [None,None,[],[]]        \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb0c832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # UNFINISHED CIRCUIT BUILDER #\n",
    "\n",
    "# from statistics import mode\n",
    "\n",
    "# def getMaxSyn(root_id, cleft_thresh):\n",
    "\n",
    "#     #sets client#\n",
    "#     client = CAVEclient(\"flywire_fafb_production\")\n",
    "    \n",
    "#     #gets current materialization version#\n",
    "#     mat_vers = max(client.materialize.get_versions())\n",
    "\n",
    "#     in_id = root_id\n",
    "\n",
    "#     upstream_list = []\n",
    "#     downstream_list = []\n",
    "    \n",
    "#     while in_id > 0:\n",
    "#         up_df = client.materialize.query_table(\n",
    "#             'synapses_nt_v1',\n",
    "#             filter_in_dict={\"post_pt_root_id\":[in_id]},\n",
    "#             materialization_version = mat_vers\n",
    "#         )\n",
    "\n",
    "#         # removes synapses below cleft threshold, 0-roots, and autapses #\n",
    "#         up_df = up_df[up_df['cleft_score'] >= cleft_thresh].reset_index(drop = True)\n",
    "#         up_df = up_df[up_df[\"pre_pt_root_id\"] != up_df[\"post_pt_root_id\"]].reset_index(drop = True)\n",
    "#         up_df = up_df[up_df[\"pre_pt_root_id\"] != 0].reset_index(drop = True)\n",
    "        \n",
    "#         strongest = mode(up_df['pre_pt_root_id'])\n",
    "#         syn_count = list(up_df['pre_pt_root_id']).count(strongest)\n",
    "\n",
    "#         if syn_count > 13 and strongest not in upstream_list:\n",
    "#             upstream_list.append(strongest)\n",
    "#             in_id = strongest\n",
    "#         else:\n",
    "#             in_id = 0\n",
    "\n",
    "#     in_id = root_id\n",
    "\n",
    "#     while in_id > 0:\n",
    "#         down_df = client.materialize.query_table(\n",
    "#             'synapses_nt_v1',\n",
    "#             filter_in_dict={\"pre_pt_root_id\":[in_id]},\n",
    "#             materialization_version = mat_vers\n",
    "#         )\n",
    "\n",
    "#         # removes synapses below cleft threshold, 0-roots, and autapses #\n",
    "#         down_df = down_df[down_df['cleft_score'] >= cleft_thresh].reset_index(drop = True)\n",
    "#         down_df = down_df[down_df[\"pre_pt_root_id\"] != down_df[\"post_pt_root_id\"]].reset_index(drop = True)\n",
    "#         down_df = down_df[down_df[\"post_pt_root_id\"] != 0].reset_index(drop = True)\n",
    "        \n",
    "#         strongest = mode(up_df['post_pt_root_id'])\n",
    "#         syn_count = list(up_df['post_pt_root_id']).count(strongest)\n",
    "\n",
    "#         if syn_count > 13 and strongest not in downstream_list:\n",
    "#             downstream_list.append(strongest)\n",
    "#             in_id = strongest\n",
    "#         else:\n",
    "#             in_id = 0\n",
    "\n",
    "#     upstream_list.reverse()\n",
    "\n",
    "#     full_list = upstream_list + [root_id] + downstream_list\n",
    "\n",
    "#     return full_list\n",
    "        \n",
    "# test = getMaxSyn(720575940628522967,50)\n",
    "\n",
    "# print(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
