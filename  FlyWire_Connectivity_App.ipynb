{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695b63ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTATIONS#\n",
    "\n",
    "# core importations\n",
    "import caveclient\n",
    "from caveclient import CAVEclient\n",
    "import cloudvolume\n",
    "from cloudvolume import CloudVolume\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# dash importations\n",
    "import dash\n",
    "from dash import Dash, dcc, html, Input, Output, State, dash_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4f1b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCTIONS#\n",
    "\n",
    "# defines function to convert nm coordinates into FlyWire-usable 4,4,40 #\n",
    "def coordConvert(coords):\n",
    "    x = coords\n",
    "    x[0] /= 4\n",
    "    x[1] /= 4\n",
    "    x[2] /= 40\n",
    "    return x\n",
    "\n",
    "# defines function to convert list of x,y,z coordinates in [4,4,40] resolution to root id #\n",
    "def coordsToRoot(coords):\n",
    "    \n",
    "    # converts coordinates to ints #\n",
    "    coords = list(map(int,coords))\n",
    "\n",
    "    # sets client #\n",
    "    client = CAVEclient(\"flywire_fafb_production\")\n",
    "\n",
    "    # sets cloud volume #\n",
    "    cv = cloudvolume.CloudVolume(\"graphene://https://prod.flywire-daf.com/segmentation/1.0/fly_v31\", use_https=True)\n",
    "\n",
    "    # determines resolution of volume #\n",
    "    res = cv.resolution\n",
    "\n",
    "    # converts coordinates using volume resolution #\n",
    "    cv_xyz = [\n",
    "        int(coords[0]/(res[0]/4)),\n",
    "        int(coords[1]/(res[1]/4)),\n",
    "        int(coords[2]/(res[2]/40))\n",
    "        ]\n",
    "\n",
    "    # sets point by passing converted coordinates into 'download_point' method #\n",
    "    point = int(cv.download_point(cv_xyz, size=1))\n",
    "\n",
    "    # looks up root id for that supervoxel using chunkedgraph, converts to string #\n",
    "    root_result = str(client.chunkedgraph.get_root_id(supervoxel_id=point))\n",
    "\n",
    "    return root_result\n",
    "\n",
    "# defines function for querying nucleus table using list of root or nuc ids #\n",
    "# and query type ('nuc' or 'root') #\n",
    "def getNuc(id_list):\n",
    "    \n",
    "    # sets client #\n",
    "    client = CAVEclient(\"flywire_fafb_production\")\n",
    "    \n",
    "    # gets current materialization version #\n",
    "    mat_vers = max(client.materialize.get_versions())\n",
    "    \n",
    "    # pulls nucleus table results based on query type #\n",
    "    if len(id_list[0]) == 7:\n",
    "        nuc_df = client.materialize.query_table(\n",
    "            'nuclei_v1',\n",
    "            filter_in_dict={\"id\": id_list},\n",
    "            materialization_version = mat_vers\n",
    "            )\n",
    "    elif len(id_list[0]) == 18:\n",
    "        nuc_df = client.materialize.query_table(\n",
    "            'nuclei_v1',\n",
    "            filter_in_dict={\"pt_root_id\": id_list},\n",
    "            materialization_version = mat_vers\n",
    "            )\n",
    "\n",
    "    # converts nucleus coordinates from n to 4x4x40 resolution #    \n",
    "    nuc_df['pt_position'] = [coordConvert(i) for i in nuc_df['pt_position']]\n",
    "    \n",
    "    # creates output dataframe using root id, nuc id, and nuc coords from table to keep alignment #\n",
    "    out_df = pd.DataFrame({\n",
    "        'Root ID':list(nuc_df['pt_root_id']),\n",
    "        'Nucleus ID':list(nuc_df['id']),\n",
    "        'Nucleus Coordinates':list(nuc_df['pt_position'])\n",
    "        })\n",
    "        \n",
    "    return out_df.astype(str)\n",
    "\n",
    "# defines function to create df of nt averages by passing: #\n",
    "# list of partner ids, pre- or post-synapse df, and matching column name #\n",
    "def ntMeans(ids,df,col_name):\n",
    "\n",
    "    # makes blank output dataframe #\n",
    "    out_df = pd.DataFrame()\n",
    "    \n",
    "    # iterates through partner ids #\n",
    "    for x in ids:\n",
    "\n",
    "        #!!! MAY BE PROBLEM !!!#\n",
    "        # filters main df to only include entries for partner #\n",
    "        partner_df = (df.loc[df[col_name] == x]).reset_index(drop = True)\n",
    "\n",
    "        # creates row dataframe and fills with nt avgs#\n",
    "        row_df = pd.DataFrame({'Partner ID':[x]})\n",
    "        row_df['Gaba Avg'] = [round(partner_df['gaba'].mean(),3)]\n",
    "        row_df['Ach Avg'] = [round(partner_df['ach'].mean(),3)]\n",
    "        row_df['Glut Avg'] = [round(partner_df['glut'].mean(),3)]\n",
    "        row_df['Oct Avg'] = [round(partner_df['oct'].mean(),3)]\n",
    "        row_df['Ser Avg'] = [round(partner_df['ser'].mean(),3)]\n",
    "        row_df['Da Avg'] = [round(partner_df['da'].mean(),3)]\n",
    "\n",
    "        # adds row df to output df #\n",
    "        out_df = out_df.append(row_df).reset_index(drop = True)\n",
    "\n",
    "    return out_df\n",
    "\n",
    "# defines function to get synapse info using root ID#\n",
    "def getSyn(root_id, cleft_thresh=0):\n",
    "\n",
    "    #sets client#\n",
    "    client = CAVEclient(\"flywire_fafb_production\")\n",
    "    \n",
    "    #gets current materialization version#\n",
    "    mat_vers = max(client.materialize.get_versions())\n",
    "    \n",
    "    #makes dfs of pre- (outgoing) and post- (incoming) synapses #\n",
    "    outgoing_syn_df = client.materialize.query_table(\n",
    "        'synapses_nt_v1',\n",
    "        filter_in_dict={\"pre_pt_root_id\":root_id},\n",
    "        materialization_version = mat_vers\n",
    "        )\n",
    "    incoming_syn_df = client.materialize.query_table(\n",
    "        'synapses_nt_v1',\n",
    "        filter_in_dict={\"post_pt_root_id\":root_id},\n",
    "        materialization_version = mat_vers\n",
    "        )\n",
    "\n",
    "    # removes synapses below cleft threshold, 0-roots, and autapses #\n",
    "    outgoing_syn_df = outgoing_syn_df[outgoing_syn_df['cleft_score'] >= cleft_thresh].reset_index(drop = True)\n",
    "    outgoing_syn_df = outgoing_syn_df[outgoing_syn_df[\"pre_pt_root_id\"] != outgoing_syn_df[\"post_pt_root_id\"]].reset_index(drop = True)\n",
    "    outgoing_syn_df = outgoing_syn_df[outgoing_syn_df[\"post_pt_root_id\"] != 0].reset_index(drop = True)\n",
    "    incoming_syn_df = incoming_syn_df[incoming_syn_df['cleft_score'] >= cleft_thresh].reset_index(drop = True)\n",
    "    incoming_syn_df = incoming_syn_df[incoming_syn_df[\"pre_pt_root_id\"] != incoming_syn_df[\"post_pt_root_id\"]].reset_index(drop = True)\n",
    "    incoming_syn_df = incoming_syn_df[incoming_syn_df[\"post_pt_root_id\"] != 0].reset_index(drop = True)\n",
    "\n",
    "    # calculates total synapses #\n",
    "    in_count = len(incoming_syn_df)\n",
    "    out_count = len(outgoing_syn_df)\n",
    "    \n",
    "    # gets lists of pre and post synaptic partners #\n",
    "    downstream_partners = list(outgoing_syn_df.drop_duplicates(subset = 'post_pt_root_id')['post_pt_root_id'])\n",
    "    upstream_partners = list(incoming_syn_df.drop_duplicates(subset = 'pre_pt_root_id')['pre_pt_root_id'])\n",
    "\n",
    "    # calculates number of upstream and downstream partners #\n",
    "    up_count = len(upstream_partners)\n",
    "    down_count = len(downstream_partners)\n",
    "\n",
    "    # builds output dataframes #\n",
    "    summary_df = pd.DataFrame({\n",
    "        'Root ID':root_id,\n",
    "        'Incoming':in_count,\n",
    "        'Outgoing':out_count,\n",
    "        'Upstream Partners':up_count,\n",
    "        'Downstream Partners':down_count\n",
    "        })\n",
    "    up_df = pd.DataFrame({'Partner ID':upstream_partners})\n",
    "    down_df = pd.DataFrame({'Partner ID':downstream_partners})\n",
    "\n",
    "    # adds number of connections between input neuron and partners #\n",
    "    up_df['Connections'] = [list(incoming_syn_df['pre_pt_root_id']).count(x) for x in upstream_partners]\n",
    "    down_df['Connections'] = [list(outgoing_syn_df['post_pt_root_id']).count(x) for x in downstream_partners]\n",
    "\n",
    "    # adds neurotransmitter averages for each partner #\n",
    "    up_df = up_df.join(\n",
    "        ntMeans(\n",
    "            upstream_partners,\n",
    "            incoming_syn_df,\n",
    "            'pre_pt_root_id'\n",
    "            ).set_index('Partner ID'), \n",
    "        on='Partner ID'\n",
    "        )\n",
    "    down_df = down_df.join(\n",
    "        ntMeans(\n",
    "            downstream_partners,\n",
    "            outgoing_syn_df,\n",
    "            'post_pt_root_id'\n",
    "            ).set_index('Partner ID'), \n",
    "        on='Partner ID'\n",
    "        )\n",
    "\n",
    "    # renames partner id columns to up/downstream #\n",
    "    up_df = up_df.rename(columns={\"Partner ID\": \"Upstream Partner ID\"})\n",
    "    down_df = down_df.rename(columns={\"Partner ID\": \"Downstream Partner ID\"})\n",
    "\n",
    "    # converts all data to strings #\n",
    "    summary_df = summary_df.astype(str)\n",
    "    up_df = up_df.astype(str)\n",
    "    down_df = down_df.astype(str)\n",
    "    \n",
    "    return [summary_df,up_df,down_df]\n",
    "\n",
    "# defines function to build dataframe using list-formatted root/nuc id or coords #\n",
    "def dfBuilder(input_list, cleft_thresh):\n",
    "\n",
    "    # if coordinates detected, converts to root #\n",
    "    if len(input_list) == 3:\n",
    "        input_list = [coordsToRoot(input_list)]\n",
    "\n",
    "    # uses root or nuc id to build nuc df #\n",
    "    nuc_df = getNuc(input_list)\n",
    "\n",
    "    # uses root id to build synapse dataframes #\n",
    "    syn_sum_df,up_df,down_df = getSyn(\n",
    "        [str(nuc_df.loc[0,'Root ID'])], \n",
    "        cleft_thresh\n",
    "        )\n",
    "\n",
    "    # joins synapse summary to nucleus df to create summary df\n",
    "    sum_df = nuc_df.join(\n",
    "        syn_sum_df.set_index('Root ID'), \n",
    "        on='Root ID'\n",
    "        )\n",
    "    \n",
    "    #returns output dataframes#\n",
    "    return [sum_df, up_df, down_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7f65b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DASH APP #\n",
    "\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "# defines layout of various app elements (submission field, checkboxes, button, output table)#\n",
    "app.layout = html.Div([\n",
    "    \n",
    "    #defines text area for instructions and feedback#\n",
    "    dcc.Textarea(\n",
    "        id='message_text',\n",
    "        value='Input root/nuc ID or coordinates and click \"Submit\" button.\\n'\\\n",
    "            'Only one entry at a time.',\n",
    "        style={'width': '500px','resize': 'none'},\n",
    "        rows=2,\n",
    "        disabled=True,\n",
    "    ),\n",
    "    \n",
    "    #defines input field#\n",
    "    html.Div(dcc.Input(  \n",
    "        id='input_field', \n",
    "        type='text', \n",
    "        placeholder='Root/Nuc ID or Coordinates',\n",
    "    )),\n",
    "    \n",
    "    html.Br(\n",
    "    ),\n",
    "\n",
    "    # defines message explaining cleft score field #\n",
    "    dcc.Textarea(\n",
    "        id='cleft_message_text',\n",
    "        value='Cleft score threshold for synapses:',\n",
    "        style={'width': '400px','resize': 'none'},\n",
    "        rows=1,\n",
    "        disabled=True,\n",
    "    ),\n",
    "\n",
    "    # defines input field for cleft score threshold #\n",
    "    html.Div(dcc.Input(  \n",
    "        id='cleft_thresh_field', \n",
    "        type='number',\n",
    "        value=50,\n",
    "        \n",
    "    )),\n",
    "\n",
    "    html.Br(\n",
    "    ),\n",
    "\n",
    "    #defines submission button#\n",
    "    html.Button(  \n",
    "        'Submit', \n",
    "        id='submit_button', \n",
    "        n_clicks=0,\n",
    "    ),\n",
    "    \n",
    "    html.Br(\n",
    "    ),\n",
    "    \n",
    "    #defines summary table#\n",
    "    html.Div(dash_table.DataTable(  \n",
    "        id='summary_table', \n",
    "        fill_width=False, #sets column width to fit text instead of expanding to container width# \n",
    "        export_format=\"csv\",\n",
    "    )),\n",
    "\n",
    "    html.Br(\n",
    "    ),\n",
    "\n",
    "    #defines incoming table#\n",
    "    html.Div(dash_table.DataTable(  \n",
    "        id='incoming_table', \n",
    "        # sets column width to fit text instead of expanding to container width #\n",
    "        # fill_width=False, \n",
    "        export_format=\"csv\",\n",
    "        style_table={'height': '200px', 'overflowY': 'auto'},\n",
    "        page_action='none',\n",
    "        fixed_rows={'headers': True},\n",
    "        style_cell={'width': 160},\n",
    "    )),\n",
    "\n",
    "    html.Br(\n",
    "    ),\n",
    "    \n",
    "    #defines outgoing table#\n",
    "    html.Div(dash_table.DataTable(  \n",
    "        id='outgoing_table', \n",
    "        # sets column width to fit text instead of expanding to container width #\n",
    "        # fill_width=False,  \n",
    "        export_format=\"csv\",\n",
    "        style_table={'height': '200px', 'overflowY': 'auto'},\n",
    "        page_action='none',\n",
    "        fixed_rows={'headers': True},\n",
    "        style_cell={'width': 160},\n",
    "    ))\n",
    "])\n",
    "\n",
    "#defines callback that takes root ids and desired data selection on button click and generates table#\n",
    "@app.callback(\n",
    "    Output('summary_table','columns'),\n",
    "    Output('summary_table', 'data'),\n",
    "    Output('incoming_table','columns'),\n",
    "    Output('incoming_table', 'data'),\n",
    "    Output('outgoing_table','columns'),\n",
    "    Output('outgoing_table', 'data'),\n",
    "    Output('message_text','value'),\n",
    "    Input('submit_button', 'n_clicks'),  #defines trigger as button press (change in the state of the 'n_clicks' aspect of 'submit_button')# \n",
    "    State('input_field', 'value'),\n",
    "    State('cleft_thresh_field','value'),\n",
    "    prevent_initial_call=True,           #prevents function from being called on page load (prior to input)#\n",
    ")\n",
    "def update_output(n_clicks, input_list, cleft_thresh):\n",
    "    \n",
    "    # splits 'ids' string into list #\n",
    "    input_list = str(input_list).split(\",\")\n",
    "    \n",
    "    # strips spaces from id_list entries and converts to integers #\n",
    "    input_list = [str(x.strip(' ')) for x in input_list]\n",
    "\n",
    "    # builds output if 1-item threshold isn't exceeded #\n",
    "    if len(input_list) == 1 or len(input_list) == 3 and len(input_list[0]) != len(input_list[2]):\n",
    "\n",
    "        # sets dataframes by passing id/coords into dfBuilder function #\n",
    "        sum_df, up_df, down_df = dfBuilder(input_list, cleft_thresh)\n",
    "\n",
    "        # creates column lists based on dataframe columns #\n",
    "        sum_column_list = [{\"name\": i, \"id\": i} for i in sum_df.columns]\n",
    "        up_column_list = [{\"name\": i, \"id\": i} for i in up_df.columns]\n",
    "        down_column_list = [{\"name\": i, \"id\": i} for i in down_df.columns]\n",
    "        \n",
    "        # makes dictionaries from dataframes #\n",
    "        sum_dict =  sum_df.to_dict('records')\n",
    "        up_dict =  up_df.to_dict('records')\n",
    "        down_dict =  down_df.to_dict('records')\n",
    "        \n",
    "        print('!!! LENGTH OF DOWN DICT:',len(down_dict))\n",
    "        print('!!! DOWN DICT[0]:',down_dict[0])\n",
    "\n",
    "        # keeps message output the same #\n",
    "        message_output = 'Input root/nuc id or coordinates and click \"Submit\" button.\\n'\\\n",
    "            'Only one entry at a time.'\n",
    "        \n",
    "        #returns list of column names, data values, and message text#\n",
    "        return [\n",
    "            sum_column_list, \n",
    "            sum_dict, \n",
    "            up_column_list, \n",
    "            up_dict, \n",
    "            down_column_list, \n",
    "            down_dict, \n",
    "            message_output\n",
    "        ]               \n",
    "    \n",
    "    # returns error message if 1-item threshold is exceeded #\n",
    "    else:\n",
    "        return [0,0,0,0,0,0,'Please limit each query to one entry.']\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    app.run_server()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
