{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695b63ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTATIONS#\n",
    "\n",
    "# core importations\n",
    "import caveclient\n",
    "from caveclient import CAVEclient\n",
    "import cloudvolume\n",
    "from cloudvolume import CloudVolume\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# dash importations\n",
    "import dash\n",
    "from dash import Dash, dcc, html, Input, Output, State, dash_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4f1b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#FUNCTIONS#\n",
    "\n",
    "# defines function to convert nm coordinates into FlyWire-usable\n",
    "def coordConvert(coords):\n",
    "    x = coords\n",
    "    x[0] /= 4\n",
    "    x[1] /= 4\n",
    "    x[2] /= 40\n",
    "    return x\n",
    "\n",
    "# defines function to convert list of coordinates in [4,4,40] resolution to root id #\n",
    "def coordsToRoot(coords):\n",
    "    \n",
    "    # sets client #\n",
    "    client = CAVEclient(\"flywire_fafb_production\")\n",
    "\n",
    "    # sets cloud volume #\n",
    "    cv = cloudvolume.CloudVolume(\"graphene://https://prod.flywire-daf.com/segmentation/1.0/fly_v31\", use_https=True)\n",
    "\n",
    "    # determines resolution of volume #\n",
    "    res = cv.resolution\n",
    "\n",
    "    # converts coordinates using volume resolution #\n",
    "    cv_xyz = [int(coords[0]/(res[0]/4)),int(coords[1]/(res[1]/4)),int(coords[2]/(res[2]/40))]\n",
    "\n",
    "    # sets point by passing converted coordinates into 'download_point' method #\n",
    "    point = int(cv.download_point(cv_xyz, size=1))\n",
    "\n",
    "    # looks up root id for that supervoxel using chunkedgraph #\n",
    "    root_result = client.chunkedgraph.get_root_id(supervoxel_id=point)\n",
    "\n",
    "    return root_result\n",
    "\n",
    "# defines function to get [list of nuc ids, list of root ids] from list of nucleus ids\n",
    "def nucToRoot(nucleus_ids):\n",
    "    \n",
    "    #sets client#\n",
    "    client = CAVEclient(\"flywire_fafb_production\")\n",
    "    \n",
    "    #determines current materialization version#\n",
    "    mat_vers = max(client.materialize.get_versions())\n",
    "    \n",
    "    #makes nuc df using root ids#\n",
    "    nuc_df = client.materialize.query_table('nuclei_v1',\n",
    "                                            filter_in_dict={\"id\": nucleus_ids},\n",
    "                                            materialization_version = mat_vers)\n",
    "    \n",
    "    #makes ouput list of root and nuc id lists aligned after possible reordering during query#\n",
    "    output_list = [nuc_df['id'].tolist(), nuc_df['pt_root_id'].tolist()]\n",
    "    \n",
    "    #returns [[nucleus ids],[root ids]]#\n",
    "    return output_list\n",
    "\n",
    "# defines function to get synapse info using root ID#\n",
    "def getSyn(root_id):\n",
    "    \n",
    "    #sets client#\n",
    "    client = CAVEclient(\"flywire_fafb_production\")\n",
    "    \n",
    "    #gets current materialization version#\n",
    "    mat_vers = max(client.materialize.get_versions())\n",
    "    \n",
    "    #makes df of presynapses (outputs)#\n",
    "    pre_syn_df = client.materialize.query_table('synapses_nt_v1', \n",
    "                                            filter_in_dict={\"pre_pt_root_id\":[root_id]})\n",
    "    \n",
    "    #makes df of postsynapses (inputs)#\n",
    "    post_syn_df = client.materialize.query_table('synapses_nt_v1', \n",
    "                                            filter_in_dict={\"post_pt_root_id\":[root_id]})\n",
    "    \n",
    "    #calculates total pre and post synapses#\n",
    "    pre_count = len(pre_syn_df)\n",
    "    post_count = len(post_syn_df)\n",
    "    \n",
    "    #calculates neurotransmitter averages#\n",
    "    pre_gaba_mean = round(pre_syn_df['gaba'].mean(),3)\n",
    "    pre_ach_mean = round(pre_syn_df['ach'].mean(),3)\n",
    "    pre_glut_mean = round(pre_syn_df['glut'].mean(),3)\n",
    "    pre_oct_mean = round(pre_syn_df['oct'].mean(),3)\n",
    "    pre_ser_mean = round(pre_syn_df['ser'].mean(),3)\n",
    "    pre_da_mean = round(pre_syn_df['da'].mean(),3)\n",
    "    post_gaba_mean = round(post_syn_df['gaba'].mean(),3)\n",
    "    post_ach_mean = round(post_syn_df['ach'].mean(),3)\n",
    "    post_glut_mean = round(post_syn_df['glut'].mean(),3)\n",
    "    post_oct_mean = round(post_syn_df['oct'].mean(),3)\n",
    "    post_ser_mean = round(post_syn_df['ser'].mean(),3)\n",
    "    post_da_mean = round(post_syn_df['da'].mean(),3)\n",
    "    \n",
    "    #gets lists of pre and post synaptic partners#\n",
    "    downstream_partners = len(pre_syn_df['post_pt_root_id'].unique())\n",
    "    upstream_partners = len(post_syn_df['pre_pt_root_id'].unique())\n",
    "\n",
    "    #makes blank output dataframe#\n",
    "    out_df = pd.DataFrame()\n",
    "    \n",
    "    #assigns columns of output dataframe#\n",
    "    out_df['Root ID'] = [root_id]\n",
    "    out_df['Post Count'] = [post_count]\n",
    "    out_df['Post Gaba Avg'] = [post_gaba_mean]\n",
    "    out_df['Post Ach Avg'] = [post_ach_mean]\n",
    "    out_df['Post Glut Avg'] = [post_glut_mean]\n",
    "    out_df['Post Oct Avg'] = [post_oct_mean]\n",
    "    out_df['Post Ser Avg'] = [post_ser_mean]\n",
    "    out_df['Post Da Avg'] = [post_da_mean]\n",
    "    out_df['Upstream Partners'] = [upstream_partners]\n",
    "    out_df['Pre Count'] = [pre_count]\n",
    "    out_df['Pre Gaba Avg'] = [pre_gaba_mean]\n",
    "    out_df['Pre Ach Avg'] = [pre_ach_mean]\n",
    "    out_df['Pre Glut Avg'] = [pre_glut_mean]\n",
    "    out_df['Pre Oct Avg'] = [pre_oct_mean]\n",
    "    out_df['Pre Ser Avg'] = [pre_ser_mean]\n",
    "    out_df['Pre Da Avg'] = [pre_da_mean]\n",
    "    out_df['Downstream Partners'] = [downstream_partners]\n",
    "    \n",
    "    #converts all data to strings#\n",
    "    out_df = out_df.astype(str)\n",
    "    \n",
    "    return out_df\n",
    "\n",
    "#defines function to build dataframe using id list or coords and query type#\n",
    "def dfBuilder(id_list,input_type):\n",
    "    \n",
    "    #converts id list to strings to avoid rounding#\n",
    "    id_list = [str(i) for i in id_list]\n",
    "    \n",
    "    \n",
    "    #creates blank dataframe with correct column titles#\n",
    "    out_df = pd.DataFrame(columns = ['Root ID','Post Count', 'Post Gaba Avg', 'Post Ach Avg', 'Post Glut Avg',\n",
    "                                     'Post Oct Avg', 'Post Ser Avg', 'Post Da Avg', 'Upstream Partners',\n",
    "                                     'Pre Count', 'Pre Gaba Avg', 'Pre Ach Avg', 'Pre Glut Avg',\n",
    "                                     'Pre Oct Avg', 'Pre Ser Avg', 'Pre Da Avg', 'Downstream Partners'])\n",
    "\n",
    "    #process if user chooses root id input#\n",
    "    if input_type == 'root':\n",
    "\n",
    "        #builds out_df by passing root ids into getSyn function#\n",
    "        for i in id_list:\n",
    "            df_row = getSyn(i)\n",
    "            out_df = out_df.append(df_row)\n",
    "    \n",
    "    #process if user chooses nucleus id input#\n",
    "    elif input_type == 'nuc':\n",
    "        \n",
    "        #passes id list into nucToRoot to get nuc_root_list#\n",
    "        nuc_root_list = nucToRoot(id_list)\n",
    "        \n",
    "        #creates single-column dataframe of nucleus ids#\n",
    "        nuc_df = pd.DataFrame(nuc_root_list[0], columns='Nucleus ID')\n",
    "        \n",
    "        #converts nuc_df data to strings to avoid issues when passing to Dash table#\n",
    "        nuc_df = nuc_df.astype(str)\n",
    "        \n",
    "        #isolates root ids into their own list#\n",
    "        root_list = nuc_root_list[1]\n",
    "        \n",
    "        #converts root ids to strings to avoid rounding and issues when passing to Dash table#\n",
    "        root_list = [str(i) for i in root_list]\n",
    "        \n",
    "        #builds out_df by passing root ids into getSyn function#\n",
    "        for i in root_list:\n",
    "            df_row = getSyn(i)\n",
    "            out_df = out_df.append(df_row)\n",
    "            \n",
    "        #joins nucleus ids to out_df#\n",
    "        out_df = nuc_df.join(out_df)\n",
    "    \n",
    "    #process if user chooses coordinate input#\n",
    "    elif input_type == 'coord':\n",
    "        \n",
    "        #converts coordinates to root id using coordToRoot function as string to avoid issues when passing to Dash table#\n",
    "        root_id = str(coordToRoot(id_list))\n",
    "        \n",
    "        #builds out_df by passing root id into getSyn function (structured to allow multiple coords in future)#\n",
    "        for i in id_list:\n",
    "            df_row = getSyn(i)\n",
    "            out_df = out_df.append(df_row)\n",
    "    \n",
    "    #reserved for error handling section, not implemented yet#\n",
    "    else:\n",
    "        print('ERROR')\n",
    "    \n",
    "    #returns output dataframe#\n",
    "    return out_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7f65b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DASH APP #\n",
    "\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "# defines layout of various app elements (submission field, checkboxes, button, output table)#\n",
    "app.layout = html.Div([\n",
    "    \n",
    "    #defines text area for instructions and feedback#\n",
    "    dcc.Textarea(\n",
    "        id='message_text',\n",
    "        value='Choose lookup method from dropdown, input coordinates, select output parameters, and click '\\\n",
    "        '\"Submit\" button.\\nID queries are limited to 20 entries, coordinate lookups must be done one at a '\\\n",
    "        'time.\\nLookup takes ~2-3 seconds per entry.',\n",
    "        style={'width': '800px','resize': 'none'},\n",
    "        rows=3,\n",
    "        disabled=True,\n",
    "    ),\n",
    "    \n",
    "    #defines input field#\n",
    "    html.Div(dcc.Input(  \n",
    "        id='input_field', \n",
    "        type='text', \n",
    "        placeholder='ID Number',\n",
    "    )),\n",
    "    \n",
    "    html.Br(\n",
    "    ),\n",
    "    \n",
    "    #defines dropdown menu for choosing query type#\n",
    "    dcc.Dropdown(\n",
    "        id='query_type',\n",
    "        options=[\n",
    "            {'label': 'Root ID', 'value': 'root'},\n",
    "            {'label': 'Nucleus ID', 'value': 'nuc'},\n",
    "            {'label': 'Coordinates (batch coordinate input not currently supported)', 'value': 'coord'},\n",
    "        ],\n",
    "        value='root',\n",
    "        style={'max-width': '500px'},\n",
    "    ),\n",
    "    \n",
    "    html.Br(\n",
    "    ),\n",
    "    \n",
    "    #defines submission button#\n",
    "    html.Button(  \n",
    "        'Submit', \n",
    "        id='submit_button', \n",
    "        n_clicks=0,\n",
    "    ),\n",
    "    \n",
    "    html.Br(\n",
    "    ),\n",
    "    \n",
    "    #defines output table#\n",
    "    html.Div(dash_table.DataTable(  \n",
    "        id='table', \n",
    "        fill_width=False, #sets column width to fit text instead of expanding to container width# \n",
    "        export_format=\"csv\",\n",
    "    ))\n",
    "])\n",
    "\n",
    "#defines callback that takes root ids and desired data selection on button click and generates table#\n",
    "@app.callback(\n",
    "    Output('table','columns'),           #defines first output location as the 'columns' aspect of 'table'#\n",
    "    Output('table', 'data'),             #defines second output location as the 'data' aspect of 'table'#\n",
    "    Output('message_text','value'),      #defines second output location as the 'data' aspect of 'table'#\n",
    "    Input('submit_button', 'n_clicks'),  #defines trigger as button press (change in the state of the 'n_clicks' aspect of 'submit_button')# \n",
    "    State('query_type', 'value'),        #defines first input state as value of 'query_type'#\n",
    "    State('input_field', 'value'),       #defines second input state as the value of 'input_field'#\n",
    "    prevent_initial_call=True,           #prevents function from being called on page load (prior to input)#\n",
    ")\n",
    "def update_output(n_clicks, query_method, ids):\n",
    "    \n",
    "    #splits 'ids' string into list#\n",
    "    id_list = str(ids).split(\",\")\n",
    "    \n",
    "    #strips spaces from id_list entries and converts to integers#\n",
    "    id_list = [int(x.strip(' ')) for x in id_list]\n",
    "    \n",
    "    #builds dataframe if 20-item threshold isn't exceeded#\n",
    "    if len(id_list) <= 20:\n",
    "        \n",
    "        #passes id list and query method into daBuilder function to make dataframe#\n",
    "        df = dfBuilder(id_list,query_method)\n",
    "        \n",
    "        #creates column list based on dataframe columns#\n",
    "        column_list = [{\"name\": i, \"id\": i} for i in df.columns]\n",
    "        \n",
    "        #makes dictionary from dataframe#\n",
    "        df_dict =  df.to_dict('records')\n",
    "        \n",
    "        #keeps message output the same#\n",
    "        message_output = 'Choose lookup method from dropdown, input coordinates, select output parameters, '\\\n",
    "            'and click \"Submit\" button.\\nID queries are limited to 20 entries, coordinate lookups must be '\\\n",
    "            'done one at a time.\\nLookup takes ~2-3 seconds per entry.'\n",
    "        \n",
    "        #returns list of column names, data values, and message text#\n",
    "        return [column_list,df_dict,message_output]               \n",
    "    \n",
    "    #returns error message if 20-item threshold is exceeded#\n",
    "    else:\n",
    "        return [0,0,'Please limit each query to a maximum of 20 id numbers.']\n",
    "        \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
